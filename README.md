# **ğŸ“š Sohamâ€™s Library â€” MERN + AI Chatbot**

A full-stack project built to practice real-world engineering: scalable architecture, React state design, database integration, and LLM-based features.

Originally a static JSON frontend, it has evolved into a **complete MERN application** with:

âœ”ï¸ A backend powered by Express + MongoDB
âœ”ï¸ A clean React + TypeScript frontend
âœ”ï¸ A fully integrated **chat popup using LangChain**
âœ”ï¸ Real database queries instead of hardcoded data

This project is actively maintained and expanded as part of my 2025 AI studies.

---

## **ğŸ”¥ What This Project Demonstrates**

* Clean, modular React components
* Migration from a static JSON setup to a full backend
* REST API design and state synchronization
* MongoDB + Mongoose models for persistent storage
* Real-world MERN app structure
* Debugging + solving local environment issues
* LLM integration using **LangChain**
* Local inference pipelines with a small LLM model

---

## **ğŸ“· Demo**

### App View

![screenshot 1](screenshot_1.png)

### Chat Popup

![screenshot 2](screenshot_2.png)

The chat window can answer basic questions about the library and interact with the user's book collection.

---

## **ğŸš€ Current Features**

### **Frontend**

* View all books stored in the MongoDB database
* Search by title
* Sort Aâ€“Z / Zâ€“A
* Filter by genre
* Collapsible sidebar
* Fully responsive layout
* Built with React + Vite + TypeScript
* **Interactive chat popup (LangChain-powered)**

### **Backend**

* Express server on `localhost:5000`
* MongoDB database with a Book schema
* `/books` API with GET and POST
* `/book/:id` API route (title, author, synopsis)
* TypeScript backend with ts-node-dev
* Clean controller/model structure

---

## **ğŸ¤– AI Integration (New)**

A built-in chat popup connects to a local LLM via **LangChain**, enabling:

* Book Q&A
* Summaries
* Genre explanations
* Conversational queries
* Simple recommendations

The system is designed for full tool integration, although current limitations of the locally running model prevent direct API calls from the LLM.
The architecture remains **future-ready**.

---

## **ğŸ›  Architecture Overview**

```
sohams-library/
  frontend/   â†’ React + Vite + TypeScript
  backend/    â†’ Node + Express + Mongoose
```

The frontend fetches all data dynamically from MongoDB.
The backend handles routing, data validation, and AI-related endpoints.

---

## **ğŸ“ˆ Roadmap**

### **Frontend**

* Add-book modal
* Image upload
* Purchased view
* Multi-page routing
* Better chat styling + typing indicators

### **Backend**

* Full CRUD (edit + delete)
* File upload support
* User accounts (optional)

### **AI**

* Fully connected retrieval system
* Proper API-augmented LLM (once model support is available)
* Richer book recommendations

---

## **ğŸ’» Tech Stack**

### Frontend

* React
* TypeScript
* Vite
* Bootstrap

### Backend

* Node.js
* Express
* MongoDB
* Mongoose
* TypeScript
* ts-node-dev

### AI

* LangChain
* Local inference pipeline

---

## **ğŸ“ Getting Started**

### 1. Clone the repo

```bash
git clone https://github.com/SohamtheCodesmith/sohams-library.git
```

---

## **ğŸš€ Running the Project**

### **Backend**

```bash
cd backend
npm install
npm run dev
```

Backend runs on `http://localhost:5000`.

Ensure MongoDB is running locally or update the connection URI for Atlas.

---

### **Frontend**

```bash
cd frontend
npm install
npm run dev
```

Frontend runs on `http://localhost:5173`.

---

## **ğŸ“Œ Notes**

This project evolves continuously, especially the chatbot system.
New features, improvements, and architectural upgrades are added periodically.